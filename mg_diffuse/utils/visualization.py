import torch
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

from os import path, cpu_count

from .json_args import JSONArgs
from .config import import_class

def load_model_args(logs_path):
    model_args_path = path.join(logs_path, 'args.json')
    return JSONArgs(model_args_path)


def load_model(model_args, logs_path, model_state_name, verbose=False):
    model_path = path.join(logs_path, model_state_name)

    if verbose:
        print(f'[ scripts/visualize_trajectories ] Loading model from {model_path}')

    model_state_dict = torch.load(model_path, weights_only=False)
    diff_model_state = model_state_dict['model']

    model_class = import_class(model_args.model)
    diffusion_class = import_class(model_args.diffusion)

    model = model_class(
        horizon=model_args.horizon,
        transition_dim=model_args.observation_dim,
        cond_dim=model_args.observation_dim,
        dim_mults=model_args.dim_mults,
        attention=model_args.attention,
    ).to(model_args.device)

    diffusion = diffusion_class(
        model=model,
        horizon=model_args.horizon,
        observation_dim=model_args.observation_dim,
        n_timesteps=model_args.n_diffusion_steps,
        loss_type=model_args.loss_type,
        clip_denoised=model_args.clip_denoised,
        predict_epsilon=model_args.predict_epsilon,
        ## loss weighting
        loss_weights=model_args.loss_weights,
        loss_discount=model_args.loss_discount,
    ).to(model_args.device)

    # Load model state dict
    diffusion.load_state_dict(diff_model_state)

    return diffusion

def plot_trajectory(trajectory):
    for i in range(len(trajectory)):
        plt.scatter(trajectory[i, 0], trajectory[i, 1], s=0.1, color="black", alpha=0.9, marker='.')


def generate_trajectories(model, model_args, start_states, only_execute_next_step, verbose=False):
    """
    Generate a trajectory from the model given the start states.

    Args:
        model: The model to generate the trajectory from.
        model_args: The arguments used to generate the model.
        start_states: The initial states to start the trajectory from.
            batch_size x observation_dim
        only_execute_next_step: If True, only execute the next step of the trajectory. (like MPC)
        verbose: If True, print progress.
    """
    if verbose:
        print('[ scripts/visualize_trajectories ] Generating trajectories')

    max_path_length = model_args.max_path_length
    batch_size = len(start_states)

    current_states = torch.tensor(start_states, dtype=torch.float32).to(model_args.device)
    current_idx = 1
    next_path_lengths = model_args.horizon - 1 if not only_execute_next_step else 1

    trajectories = np.zeros((batch_size, max_path_length, model_args.observation_dim))
    trajectories[:, 0] = np.array(start_states)

    with tqdm(total=max_path_length) as pbar:
        while current_idx < max_path_length:
            conditions = {0: current_states}

            # Forward pass to get the next states
            next_trajs = model.forward(conditions, horizon=model_args.horizon, verbose=False).trajectories

            # Check what is the size of trajectory required to reach max_path_length
            slice_path_length = min(next_path_lengths, max_path_length - current_idx)

            # Removing the start state and taking only the required path lengths
            next_trajs = next_trajs[:, 1:1 + slice_path_length]

            # Adding the next states to the trajectory
            trajectories[:, current_idx:current_idx + slice_path_length] = next_trajs.cpu().numpy()

            current_states = next_trajs[:, -1]
            current_idx += next_path_lengths

            pbar.update(slice_path_length)

    return trajectories


def process_trajectories(trajectories, model_args):
    """
    Process the trajectories to make them more interpretable.
    """
    # means = np.array([ 0.00182653, -0.00210042], dtype=np.float32)
    # stds = np.array([1.6391696 , 0.71813065], dtype=np.float32)
    #
    # trajectories = trajectories * stds + means

    return trajectories


def save_trajectories_image(trajectories, image_path, verbose=False, parallel=True):
    """
    Visualize the trajectories generated by the model.
    """

    if verbose:
        print('[ utils/visualization ] Visualizing trajectories...')



    if not parallel:
        for idx in tqdm(range(trajectories.shape[0])):
            plot_trajectory(trajectories[idx])

    else:
        from multiprocessing import Pool

        with Pool(cpu_count()-1) as pool:
            # Start pool and visualize progress with tqdm
            list(tqdm(pool.imap(plot_trajectory, trajectories), total=trajectories.shape[0]))

    plt.savefig(image_path)

    if verbose:
        print(f'[ utils/visualization ] Trajectories saved at {image_path}')


def visualize_trajectories(
        logs_path,
        model_state_name,
        only_execute_next_step=False,
        verbose=True,
        sampling_limits=(-1, 1),
        granularity=0.1,
):
    """
    Visualize the trajectories generated by the model.

    Args:
        logs_path: The path to the logs directory.
        model_state_name: The name of the model state to load.
        only_execute_next_step: If True, only execute the next step of the trajectory (like MPC)
        verbose: If True, print progress.
        sampling_limits: The limits to sample the start states from
            dim x observation_dim
        granularity: The granularity to sample the start states from
    """

    model_args = load_model_args(logs_path)
    model = load_model(model_args, logs_path, model_state_name, verbose)


    if not hasattr(sampling_limits[0], '__iter__'):
        dim = model_args.observation_dim
        sampling_limits = [sampling_limits] * dim
    else:
        assert len(sampling_limits) == model_args.observation_dim, 'Sampling limits should be of the same dimension as the observation dimension'

    # Generate a grid of start states with granularity in the range of sampling_limits inclusive
    start_states_by_dim = np.meshgrid(*[np.arange(limits[0], limits[1] + granularity, granularity) for limits in sampling_limits])

    # Flatten the grid to get all possible start state
    start_states = np.vstack([start_states_by_dim[i].flatten() for i in range(model_args.observation_dim)]).T

    trajectories = generate_trajectories(model, model_args, start_states, only_execute_next_step, verbose)

    trajectories = process_trajectories(trajectories, model_args)

    image_path = path.join(logs_path, f'trajectories{"_MPC" if only_execute_next_step else ""}.png')

    save_trajectories_image(trajectories, image_path, verbose)
