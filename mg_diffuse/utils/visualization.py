import torch
import numpy as np
from tqdm import tqdm

from os import path

import mg_diffuse.utils as utils


def load_model_args(logs_path):
    model_args_path = path.join(logs_path, 'args.json')
    return utils.JSONArgs(model_args_path)


def load_model(model_args, logs_path, model_state_name, verbose):
    model_path = path.join(logs_path, model_state_name)

    if verbose:
        print(f'[ scripts/visualize_trajectories ] Loading model from {model_path}')

    model_state_dict = torch.load(model_path, weights_only=False)
    diff_model_state = model_state_dict['model']

    model_class = utils.import_class(model_args.model)
    diffusion_class = utils.import_class(model_args.diffusion)

    model = model_class(
        horizon=model_args.horizon,
        transition_dim=model_args.observation_dim,
        cond_dim=model_args.observation_dim,
        dim_mults=model_args.dim_mults,
        attention=model_args.attention,
    ).to(model_args.device)

    diffusion = diffusion_class(
        model=model,
        horizon=model_args.horizon,
        observation_dim=model_args.observation_dim,
        n_timesteps=model_args.n_diffusion_steps,
        loss_type=model_args.loss_type,
        clip_denoised=model_args.clip_denoised,
        predict_epsilon=model_args.predict_epsilon,
        ## loss weighting
        loss_weights=model_args.loss_weights,
        loss_discount=model_args.loss_discount,
    ).to(model_args.device)

    # Load model state dict
    diffusion.load_state_dict(diff_model_state)

    return diffusion


def generate_trajectories(model, model_args, start_states, only_execute_next_step, verbose):
    """
    Generate a trajectory from the model given the start states.

    Args:
        model: The model to generate the trajectory from.
        model_args: The arguments used to generate the model.
        start_states: The initial states to start the trajectory from.
            batch_size x observation_dim
        only_execute_next_step: If True, only execute the next step of the trajectory. (like MPC)
    """
    if verbose:
        print('[ scripts/visualize_trajectories ] Generating trajectories')

    max_path_length = model_args.max_path_length
    batch_size = len(start_states)

    current_states = torch.tensor(start_states, dtype=torch.float32).to(model_args.device)
    current_idx = 1
    next_path_lengths = model_args.horizon - 1 if not only_execute_next_step else 1

    trajectories = np.zeros((batch_size, max_path_length, model_args.observation_dim))
    trajectories[:, 0] = np.array(start_states)

    with tqdm(total=max_path_length) as pbar:
        while current_idx < max_path_length:
            conditions = {0: current_states}

            # Forward pass to get the next states
            next_trajs = model.forward(conditions, horizon=model_args.horizon, verbose=False).trajectories

            # Check what is the size of trajectory required to reach max_path_length
            slice_path_length = min(next_path_lengths, max_path_length - current_idx)

            # Removing the start state and taking only the required path lengths
            next_trajs = next_trajs[:, 1:1 + slice_path_length]

            # Adding the next states to the trajectory
            trajectories[:, current_idx:current_idx + slice_path_length] = next_trajs.cpu().numpy()

            current_states = next_trajs[:, -1]
            current_idx += next_path_lengths

            pbar.update(slice_path_length)

    return trajectories


def process_trajectories(trajectories, model_args):
    """
    Process the trajectories to make them more interpretable.
    """
    # means = np.array([ 0.00182653, -0.00210042], dtype=np.float32)
    # stds = np.array([1.6391696 , 0.71813065], dtype=np.float32)
    #
    # trajectories = trajectories * stds + means

    return trajectories


def save_trajectories_image(trajectories, logs_path, only_execute_next_step, verbose):
    """
    Visualize the trajectories generated by the model.
    """

    if verbose:
        print('[ scripts/visualize_trajectories ] Visualizing trajectories...')

    import matplotlib.pyplot as plt

    for i in range(trajectories.shape[0]):
        plt.plot(trajectories[i, :, 0], trajectories[i, :, 1])

    image_path = path.join(logs_path, f'trajectories{"_MPC" if only_execute_next_step else ""}.png')

    plt.savefig(image_path)

    if verbose:
        print(f'[ scripts/visualize_trajectories ] Trajectories saved at {image_path}')


def visualize_trajectories(logs_path, model_state_name, only_execute_next_step=False, verbose=True, sampling_limits=(-1, 1), granularity=0.1):
    model_args = load_model_args(logs_path)
    model = load_model(model_args, logs_path, model_state_name, verbose)


    if not hasattr(sampling_limits[0], '__iter__'):
        dim = model_args.observation_dim
        sampling_limits = [sampling_limits] * dim
    else:
        assert len(sampling_limits) == model_args.observation_dim, 'Sampling limits should be of the same dimension as the observation dimension'

    # Generate a grid of start states with granularity in the range of sampling_limits inclusive
    start_states_by_dim = np.meshgrid(*[np.arange(limits[0], limits[1] + granularity, granularity) for limits in sampling_limits])

    # Flatten the grid to get all possible start state
    start_states = np.vstack([start_states_by_dim[i].flatten() for i in range(model_args.observation_dim)]).T

    trajectories = generate_trajectories(model, model_args, start_states, only_execute_next_step, verbose)

    trajectories = process_trajectories(trajectories, model_args)

    save_trajectories_image(trajectories, logs_path, only_execute_next_step, verbose)
